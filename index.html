
<!doctype html><html lang=en-us><head><meta name=generator content="Hugo 0.115.3"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><script src=https://code.jquery.com/jquery-3.5.1.slim.min.js integrity="sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=" crossorigin=anonymous></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css integrity=sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2 crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Nanum+Myeongjo&family=Noto+Serif+JP&family=Cormorant+Garamond&family=Libre+Baskerville&family=Source+Serif+Pro&family=Crimson+Text&family=Inter&family=Crimson+Pro&family=Literata&family=Ubuntu+Mono&family=Inter&family=Roboto"><link rel=stylesheet type=text/css href=/css/style.css><title>Cigdem Beyan</title>
</head>
<body class="container d-flex flex-column min-vh-100">
	<div class="row w-100"><div class="col w-100"><div class="about row w-100"></div>
	<div class="row w-100 justify-content-center"><img class=rounded-circle src=newMe.jpg alt=profile_picture id=profile_picture style="width:25%"></div>
	<div class="d-flex justify-content-center main_color margins_top" id=full_name><h1>Cigdem Beyan</h1></div>
	<div class="affiliations row w-100 justify-content-center">
		<div class="row w-100 justify-content-center">
			<div class="row w-100 justify-content-center" id=title-name><span class=main_color id=title>Associate Professor</span>
					 <div class="row w-100 justify-content-center text-muted" id=name class=text-muted>Department of Computer Science, University of Verona</div>

					<div class="row w-100 justify-content-center text-muted" id="title-name">
    					<a href="https://www.di.univr.it/?ent=grupporic&id=4" class="main_color">@Vision, Images, Patterns and Signals (VIPS) Research Group</a>
					</div>

					 <div class="row w-100 justify-content-center text-muted" id=name class=text-muted>Ca'vignal 2, Room 1.87</div>

					 <div class="row w-100 justify-content-center" id="title-name">
    					<a href="https://www.iit.it/it/web/guest/people-details?line=14601" class="main_color" id="title">Affiliated Researcher in AI for GOOD (AIGO) Lab @Istituto Italiano di Tecnologia</a>
					</div>


					 <div class="row w-100 justify-content-center text-muted" id=email>cigdem.beyan[at]univr[dot]it</div>
					<div class="row w-100 justify-content-center text-muted"> </div>
				</div>
			</div>
			<div class="socials d-flex justify-content-center margins">
				<div class="row w-100 justify-content-center">
					<a class="main_color margins_around" rel=me href='https://scholar.google.com/citations?hl=en&amp;user=VmjUxckAAAAJ&hl&amp;view_op=list_works&amp;sortby=pubdate' target=_blank><i class="ai ai-2x ai-google-scholar academic_icons_customize"></i></a>
					<a class="main_color margins_around" rel=me href=https://github.com/cbeyan target=_blank><i data-feather=github></i></a>
					<a class="main_color margins_around" rel=me href=https://twitter.com/BeyanCigdem target=_blank><i data-feather=twitter></i></a>
					<a class="main_color margins_around" rel=me href=https://www.linkedin.com/in/cigdem-beyan-53954537/ target=_blank><i data-feather=linkedin></i></a>
					<a class="main_color margins_around" href=cv.pdf target=_blank><i class="ai ai-2x ai-cv academic_icons_customize"></i></a>
				</div>
			</div>
			<div class="introduction row w-100 text-justify"><div class="col w-100">
				<p> 
					<b> Cigdem Beyan </b> holds the position of Associate Professor (INFO-01/A - Informatics) in the Department of Computer Science at the <a href="https://www.di.univr.it/?ent=persona&id=80405&lang=it"> University of Verona</a>, Italy. Her research interests primarily lie in the areas of computer vision, machine learning, social signal processing, affective computing, and human/animal behavior analysis. Cigdem has co-authored more than 60 peer-reviewed scientific articles and regularly publishes in top-tier journals and conferences in computer vision, multimedia, and social/affective computing. She serves as a reviewer for several journals in multimedia, affective computing, computer vision, and machine learning (e.g., IEEE Trans. PAMI, IEEE Trans. Multimedia, IEEE Trans. Affective Computing, Pattern Recognition), and as an Area Chair for major IEEE/ACM/IAPR/BMVA conferences (e.g., CVPR, ECCV, ICML, WACV, ACM MM, BMVC, ACM ICMI, ICLR). She is a member of IEEE, ACM, and ELLIS. Additionally, she has been actively involved in organizing conferences in the fields of computer vision, social robotics, human-computer interaction, and biometrics. Since 2014, she has been recognized as an Associate Fellow of the Higher Education Academy for her achievement against the UK Professional Standards Framework for teaching and learning support in higher education.
				</p>
				<p> <b> Previous positions: </b> University of Edinburgh (Ph.D.), Istituto Italiano di Tecnologia (PostDoc), University of Trento (Assistant Prof.), University of Bergamo (Tenure-track Assistant Prof.). 
				</p>
			</div>
		</div>
	</div>
	<div class="about row w-100">
		
	</div>
	</div>
	</div>
	<div class="row w-100">
		<div class="col w-100"><div class="row w-100"><div class="col w-100"><h3 class="row w-100 section-title main_color">News</h3></div></div>
		<div class="news row w-100">
			<div class="col w-100"><ul class=news_list>

				<li>
  				<i data-feather="paperclip"></i> 
  				Our paper "Dynamic Scoring with Enhanced Semantics for Training-Free Human-Object Interaction Detection"
  				has been accepted to 
  				<a href="https://acmmm2025.org/" target="_blank">ACM Multimedia 2025</a>.
  				<a href="https://github.com/francescotonini/dysco" target="_blank">[Code]</a> 
  				<a href="https://arxiv.org/abs/2507.17456" target="_blank">[Paper (pre-submission)]</a> 
  				Congrats to 
  				<a href="https://scholar.google.com/citations?user=tRTTFOwAAAAJ&hl=it" target="_blank">Francesco Tonini!</a>
				</li>


				<li>
  				<i data-feather="paperclip"></i> 
  				Our paper "MADPOT: Medical Anomaly Detection with CLIP Adaptation and Partial Optimal Transport"
  				has been accepted for <strong>oral presentation</strong> at 
  				<a href="https://sites.google.com/view/iciap25" target="_blank">ICIAP 2025</a>. 
  				<a href="https://github.com/mahshid1998/MADPOT" target="_blank">[Code]</a> 
  				<a href="https://arxiv.org/abs/2507.06733" target="_blank">[Paper (pre-submission)]</a>
				</li>

				<li><i data-feather=award></i> <a target=_blank>Excited to join the Editorial Board of IEEE Transactions on Affective Computing<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5165369"></a> as an <b>Associate Editor</b>. I look forward to contributing to advancing research and supporting the community in our dynamic field. </a></li>

				<li><i data-feather=award></i> <a target=_blank>Pleased to be recognized once again as an <b>Outstanding Reviewer</b> for <a href="https://cvpr.thecvf.com/Conferences/2025/ProgramCommittee#all-outstanding-reviewer">CVPR 2025</a> (Top 5.6%). Glad to contribute to the community through reviewing.</a></li>


				<li><i data-feather=paperclip></i> <a target=_blank>Our paper "MadCLIP: Few-shot Medical Anomaly Detection with CLIP"</a> has been accepted to <a href="https://conferences.miccai.org/2025/en/"> MICCAI 2025</a>, ranking in the top 9% out of 3667 submissions. Congrats to <a href="https://scholar.google.com/citations?user=7XWvNE4AAAAJ&hl=en">Mahshid Shiri!</a> <a href="https://github.com/mahshid1998/MadCLIP" target="_blank">[Code]</a> <a href="https://arxiv.org/abs/2506.23810" target="_blank">[Paper (pre-submission)]</a></li>

				<li><i data-feather=paperclip></i> Our paper <a target=_blank href="https://dl.acm.org/doi/10.1145/3715668.3736334"> "Toward Modeling Commensal Interactions in Human Dyads"</a> has been accepted to <a href="https://conferences.miccai.org/2025/en/"> ACM Designing Interactive Systems Conference (DIS) 2025</a>, which is another output of <a href="https://cocoa-research.github.io/"> COCOA project!</a></li>


				<li><i data-feather=calendar></i> <a target=_blank> I once again serve as an <b>Area Chair</b> for the <a href="https://bmvc2025.bmva.org/">British Machine Vision Conference (BMVC)</a> and <a href="https://icmi.acm.org/2025/"> ACM International Conference on Multimodal Interaction (ICMI) </a> 
				this year.</a></li>

				<li><i data-feather=calendar></i> <a target=_blank> Delivered a Ph.D course on <b> Foundations of Multimodal Learning </b> at the Sapienza University of Rome. Thanks for having me! </a></li>

				<li><i data-feather=paperclip></i> <a target=_blank>Our paper <a href="https://www.mdpi.com/2078-2489/16/3/233"> VAD-CLVA: Integrating CLIP with LLaVA for Voice Activity Detection </a> has been accepted in Information Journal. Congrats to Andrea Appiani on achieving such success with his Master's thesis!</a> </span></li>

				<li><i data-feather=calendar></i> I haven't had time to post updates here :(. Resuming in March 2025...</li>

				<li><i data-feather=calendar></i> <a target=_blank> I'm serving as an <b> AC </b> at the <a href="https://icmi.acm.org/2025/"> 27th ACM International Conference on Multimodal Interaction (ACM ICMI 2025). </a></li>

				<li><i data-feather=calendar></i> <a target=_blank> I'm serving as an <b> Associate Editor </b> at the <a href="https://2025.ieee-icra.org/"> IEEE International Conference on Robotics and Automation (ICRA 2025). </a></li>
				
				<li><i data-feather="calendar"></i>	I will be talking about <b>recent methods and ongoing challenges in gaze target detection </b> at the <a href="https://expressive-encounters-workshop.github.io/2024/" target="_blank">Expressive Encounters Workshop </a> organized in conjunction with ECCV 2024. <a href='ECCVw24_KeynoteCB_gaze.pdf'>Slides</a> are available, enjoy! </li>
				
				<li><i data-feather=paperclip></i> <a target=_blank>Our paper <a href="https://sites.google.com/view/t-cap-2024/program"> Upper-Body Pose-based Gaze Estimation for Privacy-Preserving 3D Gaze Target Detection </a> has been accepted at ECCV Workshop (<b>T-CAP</b>). Congrats <a href="https://scholar.google.com/citations?user=mDMfbggAAAAJ&hl=it"> Andrea Toaiari</a>. </span></li>

				<li><i data-feather=paperclip></i> <a target=_blank>Our paper <a href="https://github.com/francescotonini/al-gtd"> AL-GTD: Deep Active Learning for Gaze Target Detection </a> has been accepted at 32th ACM International Conference on Multimedia (<b>ACM MM'24</b>). Congrats <a href="https://scholar.google.com/citations?user=tRTTFOwAAAAJ&hl=it"> Francesco Tonini</a>. </span></li>

				<li><i data-feather=paperclip></i> <a target=_blank>Our paper <a href="https://icmi.acm.org/2024/"> Automatic Recognition of Commensal Activities in Co-located and Online Settings </a> has been accepted at 26th ACM International Conference on Multimodal Interaction (<b>ACM ICMI</b>). Congrats the team of <a href="https://cocoa-research.github.io/"> COCOA project </a>team! </span></li>

				<li><i data-feather=paperclip></i> <a target=_blank>Paper <a href="https://github.com/AnilOsmanTur/Zero-shot-Retail-Product-Classification"> Exploring Fine-grained Retail Product Discrimination with Zero-shot Object Classification Using Vision-Language Models </a> has been accepted at IEEE 8th Forum on Research and Technologies for Society and Industry Innovation (<b>RTSI</b>). Congrats our industrial Ph.D. student <a href="https://scholar.google.com/citations?user=W4yNf8UAAAAJ&hl=en"> Anil Osman Tur</a>! </span></li>

				<li><i data-feather=paperclip></i> <a target=_blank>Paper <a href="https://www.sciencedirect.com/science/article/pii/S1574954124002759"> Trajectory-based fish event classification through pre-training with diffusion models </a> has been accepted at <b>Ecological Informatics</b>! Congrats <a href="https://www.linkedin.com/in/noemi-canovi/?locale=en_US"> Noemi Canovi </a> and all CoastVision team for the hard work! </span></li>

				<li><i data-feather=award></i> <a target=_blank> A new PROJECT: <a href="https://www.di.univr.it/?ent=progetto&id=5994&lang=it"> Transfer And Adaptive Learning In Imperfect Multimodal Data Scenarios - Talim </a> funded by MUR - Ministero dell'Università e della Ricerca!</li>

				<li><i data-feather=award></i> <a target=_blank> Exciting news!!!! We currently have several PhD student positions available at UNIVR's Department of Computer Science, each offering scholarships. Take a look at the details <a href="https://www.corsi.univr.it/?ent=cs&id=635&menu=iscriversi&tab=comeiscriversi&lang=en"> here </a>and don't hesitate to reach out if you're interested! The deadline for applications is May 23 at 12:00 PM!</li>

				<li><i data-feather=calendar></i> <a target=_blank> Also this year, I will be serving as an <b> Area Chair </b> at the <a href="https://bmvc2024.org/"> British Machine Vision Conference (BMVC). </a> Looking forward to have a productive review and discussion period at BMVC 2024!! </li>

				<li><i data-feather=paperclip></i> <a target=_blank>Paper <a href="https://ieeexplore.ieee.org/document/10510440?source=authoralert">	
Anticipating Next Active Objects for Egocentric Videos </a> has been accepted at IEEE Access! Congrats to <a href=https://scholar.google.com/citations?user=pM6-D7EAAAAJ&hl=en>Sanket Kumar Thakur</a>.</span></li>

				<li><i data-feather=paperclip></i> <a target=_blank>Paper <a href="https://avi2024.dibris.unige.it/program">	
Diffusion-Based Unsupervised Pre-training for Automated Recognition of Vitality Forms </a> has been accepted at AVI 2024! I  congratulate my two Master's students: Noemi Canovi and Federico Montagna, for this succes! </span></li>
				
				<li><i data-feather=award></i> <a target=_blank> Super happy to announce that I joined the <b> University of Verona </b>, <a href="https://www.di.univr.it/?ent=persona&id=80405&lang=it"> Department of Computer Science as an Associate Professor. </a> </li>

				<li><i data-feather=calendar></i> <a target=_blank> Happy to be a <b> Senior Committee Member </b> at the <a href="https://icmi.acm.org/2024/"> 26th ACM International Conference on Multimodal Interaction (ACM ICMI 2024)</a>!</li>

				<li><i data-feather=calendar></i> <a target=_blank> Delighted to be a <b> Senior Committee Member </b> at the <a href="https://acii-conf.net/"> 12th International Conference on Affective Computing and Intelligent Interaction (ACII 2024)</a>!</li>

				<li><i data-feather=calendar></i> <a target=_blank> Exciting news! I am serving as a <b> Doctoral Consortium Co-chair </b> at the <a href="https://eccv.eventhosts.cc/"> 18th European Conference on Computer Vision (ECCV 2024)</a>!</li>

				<li><i data-feather=calendar></i> <a target=_blank> Thrilled to serve as an <b> Area Chair </b> at the <a href="https://eccv.eventhosts.cc/"> 18th European Conference on Computer Vision (ECCV 2024)</a>!</li>

				<li><i data-feather=calendar></i> <a target=_blank> Delighted to be appointed as an <b> Area Chair </b> at the <a href="https://eccv.eventhosts.cc/"> 26th ACM International Conference on Multimodal Interaction (ACM ICMI 2024)</a>!</li>

				<li><i data-feather=calendar></i> <a target=_blank>I am serving as a <b> Social Media Co-chair </b> at the <a href="https://www.ro-man2024.org"> 33rd IEEE International Conference on Robot and Human Interactive Communication (IEEE RO-MAN 2024)</a>!</li>

				<li><i data-feather=paperclip></i> <a target=_blank>Paper <a href="https://arxiv.org/abs/2207.10574"> Co-Located Human-Human Interaction Analysis using Nonverbal Cues: A Survey </a> is accepted at ACM Computing Surveys!</span></li>

				<li><i data-feather=calendar></i> <a target=_blank>I am serving as an <b> Associate Editor </b> at the <a href="https://2024.ieee-icra.org/"> 2024 IEEE International Conference on Robotics and Automation (ICRA)! </a></li>

				<li><i data-feather=award></i> From September 2023, I am with the Department of Management, Information, and Production Engineering (DIGIP) at the University of Bergamo as a <b> Tenure Track Assistant Professor</b>.</span></li>

				<li><i data-feather=calendar></i> <a target=_blank>I am serving as a <b> Proceedings Co-chair </b> at the <a href="https://avi2024.dibris.unige.it/">International Conference on Advanced Visual Interfaces 2024</a>!</li>

				<li><i data-feather=calendar></i> <a target=_blank>I am serving as a <b> Publicity Co-chair </b> at the <a href="https://ieee-arso.org/"> 20th IEEE International Conference on Advanced Robotics and Its Social Impacts (ARSO 2024)</a>!</li>

				<li><i data-feather=paperclip></i> <a  target=_blank>Paper accepted at <b> WACV 2024</b>!</a> <span class="secondary_font text-muted"> The paper entitled &lsquo;Leveraging Next-Active Objects for Context-Aware Anticipation in Egocentric Videos&rsquo; has been accepted at WACV 2024. Congrats to <a href=https://scholar.google.com/citations?user=pM6-D7EAAAAJ&hl=en>Sanket Kumar Thakur</a>.</span></li>

				<li><i data-feather=paperclip></i> <a target=_blank>Paper <a href="https://ieeexplore.ieee.org/abstract/document/10227296">Unleashing the Transferability Power of Unsupervised Pre-Training for Emotion Recognition in Masked and Unmasked Facial Images </a> is accepted at IEEE Access!</span></li>

				<li><i data-feather=paperclip></i> <a target=_blank>Paper <a href="https://www.frontiersin.org/articles/10.3389/fcomp.2023.1203901/abstract">SKELTER: Unsupervised Skeleton Action Denoising and Recognition using Transformers </a> is accepted at Frontiers in Computer Science! Congrats to <a href=https://scholar.google.com/citations?user=X8FU5xMAAAAJ&hl=it>Giancarlo Paoletti</a>.</span></li>


				<li><i data-feather=paperclip></i> <a href=https://twitter.com/toninifrancesco/status/1679760714225819649 target=_blank>Paper accepted at <b>ICCV 2023</b>!</a> <span class="secondary_font text-muted"> The paper entitled &lsquo;Object-aware Gaze Target Detection&rsquo; has been accepted at ICCV 2023. Congrats to <a href=https://scholar.google.com/citations?user=tRTTFOwAAAAJ&hl=it>Francesco Tonini</a> and <a href=https://scholar.google.com/citations?user=e7lgiYYAAAAJ&hl=zh-TW>Nicola Dall'Asen</a>.</span></li>

				<li><i data-feather=paperclip></i> <a target=_blank>Paper accepted at ICIAP 2023!</a> <span class="secondary_font text-muted"> The paper entitled &lsquo;Unsupervised Video Anomaly Detection with Diffusion Models Conditioned on Compact Motion Representations&rsquo; has been accepted at <b>ICIAP 2023</b> as <b>ORAL</b> presentation. Congrats to <a href=https://scholar.google.com/citations?user=W4yNf8UAAAAJ&hl=en>Anil Osman Tur</a> and <a href=https://scholar.google.com/citations?user=e7lgiYYAAAAJ&hl=zh-TW>Nicola Dall'Asen</a>.</span></li>

				<li><i data-feather=paperclip></i> <a href=https://twitter.com/fodark/status/1676130664205152256 target=_blank>Paper accepted at <b>ICIP 2023</b>!</a> <span class="secondary_font text-muted"> The paper entitled &lsquo;Exploring Diffusion Models for Unsupervised Video Anomaly Detection&rsquo; has been accepted at ICIP 2023 as <b>ORAL</b> presentation. Congrats to <a href=https://scholar.google.com/citations?user=W4yNf8UAAAAJ&hl=en>Anil Osman Tur</a> and <a href=https://scholar.google.com/citations?user=e7lgiYYAAAAJ&hl=zh-TW>Nicola Dall'Asen</a>.</span></li>

				<li><i data-feather=paperclip></i> <a  target=_blank>Paper accepted at <b> ICIP 2023</b>!</a> <span class="secondary_font text-muted"> The paper entitled &lsquo;Enhancing Next Active Object-based Egocentric Action Anticipation with Guided Attention&rsquo; has been accepted at ICIP 2023. Congrats to <a href=https://scholar.google.com/citations?user=pM6-D7EAAAAJ&hl=en>Sanket Kumar Thakur</a>.</span></li>

				<li><i data-feather=award></i> <a target=_blank>We are the <b>1st place winner</b> of the 2023 <a href="https://ego4d-data.org/docs/challenge/">Ego4D </a> Challenge in the Forecasting: Short-term hand object prediction track in <b>CVPR 2023</b>. </a> <span class="secondary_font text-muted"> The paper summarizing our methodology can be found in <a href=https://arxiv.org/abs/2305.16066>HERE</a>. Congrats to <a href=https://scholar.google.com/citations?user=pM6-D7EAAAAJ&hl=en>Sanket Kumar Thakur</a>.</span></li>

				<li><i data-feather=calendar></i> <a target=_blank>I am serving as the <b> Demo and Exhibition Chair </b> at the <a href="https://fg2024.ieee-biometrics.org/">18th IEEE International Conference on Automatic Face and Gesture Recognition (IEEE FG) </a>!</li>

				<li><i data-feather=calendar></i> <a target=_blank>I am serving as an <b> Area Chair </b> at the <a href="https://bmvc2023.org/"> 34th British Machine Vision Conference (BMVC) </a>!</li>

				<li><i data-feather=calendar></i> <a target=_blank>We are organizing a <b> Special Issue </b> called Social and Cognitive Interactions in the Open World at International Journal of Social Robotics! <span class="secondary_font text-muted"> Check out the <a href=https://www.springer.com/journal/12369/updates/24073292>CALL</a> for more information.</span></li>

				<li><i data-feather=layout></i> A new version (aka simplified) of the website is now ON! <span class="secondary_font text-muted"> </span></li>
			</ul>
		</div>
	</div>
</div>
</div>


	<div class="row w-100">
		<div class="col w-100"><div class="row w-100"><div class="col w-100"><h3 class="row w-100 section-title main_color">Teaching</h3></div></div>
		<div class="news row w-100">
			<div class="col w-100"><ul class=news_list>
				
				<li><a target=_blank><a href=https://www.corsi.univr.it/?ent=cs&aa=2024%2F2025&codiceCs=S84&codins=4S010675&discr=&discrCd=&id=1046&menu=studiare&tab=insegnamenti> Advanced Programming for AI </a> LM in Artificial Intelligence @UNIVR - Spring 2025 [48h] </span></li>

				<li><a target=_blank><a href=https://www.corsi.univr.it/?ent=cs&aa=2024%2F2025&codiceCs=S84&codins=4S010673&discr=&discrCd=&id=1046&menu=studiare&tab=insegnamenti> Machine Learning and Deep Learning </a> LM in Artificial Intelligence @UNIVR - Fall/Spring 2025 [60h]</span></li>

				<li><a target=_blank><a href=https://www.corsi.univr.it/?ent=cs&aa=2024%2F2025&codiceCs=S84&codins=4S010680&discr=&discrCd=&id=1046&menu=studiare&tab=insegnamenti> HCI-Multimodal Systems </a> LM in Artificial Intelligence @UNIVR - Fall 2025 [12h]</span></li>

				<li><a target=_blank><a href=https://www.corsi.univr.it/?ent=cs&id=635&menu=studiare&tab=insegnamenti&codiceCs=DR-I226&codins=DT000782&aa=2023/2024&lang=en> Multimodal Learning and Applications </a> PhD in Computer Science @UNIVR - Spring 2024 [20h]</span></li>

				<li><a target=_blank><a href=https://www.corsi.univr.it/?ent=cs&aa=2023%2F2024&codiceCs=S81&codins=4S009001&discr=&discrCd=&id=954&menu=Studiare&tab=Insegnamenti> Machine Learning & Artificial Intelligence </a> LM in Computer Engineering for Robotics and Smart Industry @UNIVR - Spring 2024 [24h]</span></li>
				
				<li><a target=_blank><a href=https://unibg.unifind.cineca.it/individual?uri=http%3A%2F%2Firises.unibg.it%2Fresource%2Faf%2F76991-PDS-2017-3-6-48> INFORMATICA (CDL 23) </a> LT Ingegneria Meccanica @UNIBG - Fall 2023 [10h]</span></li>
				
				<li><a target=_blank><a href=https://didatticaonline.unitn.it/dol/enrol/index.php?id=34617>Introduction to Machine learning </a> LM Data Science @UNITN - Spring 2023 [24h]</span></li>
				
				<li><a target=_blank><a href=https://didatticaonline.unitn.it/dol/enrol/index.php?id=33325>Introduction to Machine learning </a> LM Data Science @UNITN - Spring 2022 [24h]</span></li>
				
				<li><a target=_blank><a href=https://ict.unitn.it/node/1165>Multimodal Machine learning </a> PhD Course @UNITN - Spring 2022 [10h]</span></li>
				<li><a target=_blank><a href=https://www.i-aida.org/course/human-behavior-analysis-with-a-social-signal-processing-perspective/>Human Behavior Analysis with a Social Signal Processing Perspective </a> Short Course for PhD and early career researchers @AIDA - Spring 2022 [4h]</span></li>

			</ul>
		</div>
	</div>
</div>
</div>

	
<div class="row w-100">
		<div class="col w-100"><div class="row w-100"><div class="col w-100"><h3 class="row w-100 section-title main_color">People</h3></div></div>

		<div class="col w-100">
  			<h3>Current</h3>
  			<ul class="news_list">
  				<li><a target=_blank>Ehsan Karimi (UNIVR, Msc Intern)</a></li>
  				<li><a target=_blank>Chiara Venturi (UNIVR, Msc w/Luxottica)</a></li>
  				<li><a target=_blank>Emil Alizada (UNIVR, Msc with Vittorio Murino)</a></li>
  				<li><a target=_blank>Mahdi Beigzadeh Aghabagher (UNIVR, Msc with Vittorio Murino)</a></li>
  				<li><a target=_blank>Anil Osman Tur (UNIVR, PostDoc)</a></li>
  				<li><a target=_blank>Fanqi Yu (IIT, Ph.D. with Vittorio Murino)</a></li>
    			<li><a target=_blank>Francesco Tonini (UNITN, Ph.D. with Elisa Ricci and Cees Snoek)</a></li>
  			</ul>

  			<h3>Past</h3>
  			<ul class="news_list">
  				<li><a target=_blank>Mahshid Shiri (UNIVR, Research Fellow with Vittorio Murino)</a></li>
  				<li><a target=_blank>Andrea Toaiari (UNIVR, Ph.D. with Marco Cristani)</a></li>
  				<li><a target=_blank>Anil Osman Tur (UNITN, Ph.D. with Elisa Ricci)</a></li>
    			<li><a target=_blank>Sanket Thakur (IIT, Ph.D. with Alessio Del Bue)</a></li>
    			<li><a target=_blank>Giancarlo Paoletti (IIT, Ph.D. with Alessio Del Bue)</a></li>
    			<li><a target=_blank>Muhammad Shahid (IIT, Ph.D. with Vittorio Murino)</a></li>
    			<li><a target=_blank>Nicolò Carissimi (IIT, Ph.D. with Vittorio Murino)</a></li>
    			<li><a target=_blank>Andrea Appiani (UNIBG, Msc)</a></li>
    			<li><a target=_blank>Gianmarco Antignani (UNITN, Msc with Nicu Sebe)</a></li>
    			<li><a target=_blank>Noemi Canovi (UNITN, Msc)</a></li>
    			<li><a target=_blank>Martina Rama (UNITN, Msc with Elisa Ricci)</a></li>
    			<li><a target=_blank>Francesco Tonini (UNITN, Msc with Elisa Ricci)</a></li>
    			<li><a target=_blank>Federico Montagna (UNITN, Bsc with Nicu Sebe and Radoslaw Niewiadomski)</a></li>
    			<li><a target=_blank>Kheder Yazgi (UNITN, Msc Intern)</a></li>
    			<li><a target=_blank>Noemi Canovi (UNITN, Msc Intern)</a></li>
    			<li><a target=_blank>Martina Rama (UNITN, Msc Intern)</a></li>

  			</ul>
		</div>


		</div>
	</div>
</div>
</div>


<div class="col w-100"><div class="row w-100"><div class="col w-100"><h3 class="row w-100 section-title main_color">Recent Research </h3><h6 class="row w-100 section-subtitle text-muted">I'm not able to keep this very up-to-date. Please refer to my <a href="https://scholar.google.com/citations?hl=en&user=VmjUxckAAAAJ&"> &nbspgoogle scholar profile&nbsp </a> for a more concrete info.</h6></div></div>

<div class="publications row w-100">
	<div class="col w-100">

		<div class="publication row w-100">
			<div class=col-3><img id=pub_picture src=acmmm25.png width="213" height="66"></div>
			<div class=col-9>
				<div class="section-1 w-100"><span>Dynamic Scoring with Enhanced Semantics for Training-Free Human-Object Interaction Detection,</span> <span class="text-muted publication-date">2025,</span> <span class="text-muted publication-name">ACM Multimedia</span></div>
				<div class="section-2 text-muted w-100"><span>Tonini, F.</span> <span class=separator>,</span> <span>Vaquero, L.</span> <span class=separator>,</span> <span>Conti, A.</span> <span class=separator>,</span> <span>Beyan, C.</span> <span class=separator>,</span> <span> and Ricci, E.</span></div>
				<div class="section-3 w-100"><a class="main_color text-decoration-none rounded" href=https://github.com/francescotonini/dysco target=_blank>code</a> <a class="main_color text-decoration-none rounded" href=https://arxiv.org/abs/2507.17456 target=_blank>arxiv</a></div>
			</div>
		</div>


		<div class="publication row w-100">
			<div class=col-3><img id=pub_picture src=acmmm2024.png width="213" height="66"></div>
			<div class=col-9>
				<div class="section-1 w-100"><span>AL-GTD: Deep Active Learning for Gaze Target Detection,</span> <span class="text-muted publication-date">2024,</span> <span class="text-muted publication-name">ACM Multimedia</span></div>
				<div class="section-2 text-muted w-100"><span>Tonini, F.</span> <span class=separator>,</span> <span>Dall'Asen, N.</span> <span class=separator>,</span> <span>Vaquero, L.</span> <span class=separator>,</span> <span>Beyan, C.</span> <span class=separator>,</span> <span> and Ricci, E.</span></div>
				<div class="section-3 w-100"><a class="main_color text-decoration-none rounded" href=https://github.com/francescotonini/al-gtd target=_blank>code</a> <a class="main_color text-decoration-none rounded" href=https://arxiv.org/abs/2409.18561 target=_blank>arxiv</a></div>
			</div>
		</div>
		
		<div class="publication row w-100">
			<div class=col-3><img id=pub_picture src=wacv2024.png width="213" height="66"></div>
			<div class=col-9>
				<div class="section-1 w-100"><span>Leveraging Next-Active Objects for Context-Aware Anticipation in Egocentric Videos,</span> <span class="text-muted publication-date">2024,</span> <span class="text-muted publication-name">WACV</span></div>
				<div class="section-2 text-muted w-100"><span>Thakur, S.</span> <span class=separator>,</span> <span>Beyan, C.</span> <span class=separator>,</span> <span>Morerio, P.</span> <span class=separator>,</span> <span>Murino, V.</span> <span class=separator>,</span> <span> and Del Bue, A.</span></div>
				<div class="section-3 w-100"><a class="main_color text-decoration-none rounded" href=https://sanketsans.github.io/leverage-next-active-object-action-anticipation.html target=_blank>code</a> <a class="main_color text-decoration-none rounded" href=https://arxiv.org/abs/2308.08303 target=_blank>arxiv</a></div>
			</div>
		</div>


		<div class="publication row w-100">
			<div class=col-3><img id=pub_picture src=ICCV2023.png width="213" height="66"></div>
			<div class=col-9>
				<div class="section-1 w-100"><span>Object-aware Gaze Target Detection,</span> <span class="text-muted publication-date">2023,</span> <span class="text-muted publication-name">ICCV</span></div>
				<div class="section-2 text-muted w-100"><span>Tonini, F.</span> <span class=separator>,</span> <span>Dall'Asen, N.</span> <span class=separator>,</span> <span>Beyan, C.</span> <span class=separator>,</span> <span> and Ricci, E.</span></div>
				<div class="section-3 w-100"><a class="main_color text-decoration-none rounded" href=https://github.com/francescotonini/object-aware-gaze-target-detection target=_blank>code</a> <a class="main_color text-decoration-none rounded" href=https://arxiv.org/abs/2307.09662 target=_blank>arxiv</a></div>
			</div>
		</div>

		<div class="publication row w-100">
			<div class=col-3><img id=pub_picture src=ICIP2023.png width="213" height="66"></div>
			<div class=col-9>
				<div class="section-1 w-100"><span>Exploring Diffusion Models for Unsupervised Video Anomaly Detection,</span> <span class="text-muted publication-date">2023,</span> <span class="text-muted publication-name">ICIP</span></div>
				<div class="section-2 text-muted w-100"><span>Tur, O. A.,</span><span class=separator>,</span><span>Dall'Asen, N.</span><span class=separator>,</span><span>Beyan, C.</span><span> and Ricci, E.</span></div>
				<div class="section-3 w-100"><a class="main_color text-decoration-none rounded" href=https://github.com/AnilOsmanTur/video_anomaly_diffusion target=_blank>code</a><a class="main_color text-decoration-none rounded" href=https://arxiv.org/pdf/2304.05841 target=_blank> arxiv</a></div>
			</div>
		</div>

		<div class="publication row w-100">
			<div class=col-3><img id=pub_picture src=ICIP2023Sanket.png width="213" height="66"></div>
			<div class=col-9>
				<div class="section-1 w-100"><span>Enhancing Next Active Object-based Egocentric Action Anticipation with Guided Attention,</span> <span class="text-muted publication-date">2023,</span> <span class="text-muted publication-name">ICIP</span></div>
				<div class="section-2 text-muted w-100"><span>Thakur, S.</span><span class=separator>,</span><span>Beyan, C.</span><span class=separator>,</span><span>Morerio, P.</span><span class=separator>,</span><span>Murino, V.</span><span class=separator>,</span><span> and Del Bue, A.</span></div>
				<div class="section-3 w-100"><a class="main_color text-decoration-none rounded" href=https://sanketsans.github.io/guided-attention-egocentric.html target=_blank>code</a><a class="main_color text-decoration-none rounded" href=https://arxiv.org/abs/2305.12953 target=_blank> arxiv</a></div>
			</div>
		</div>



	</div>
</div>
</div>
</div>















			<footer class="mt-auto d-flex justify-content-center text-muted small secondary_font"><span class=text-muted>Copyright (c) 2023, Cigdem Beyan, <a class=text-muted href=https://github.com/hadisinaee/avicenna target=_blank>created by Avicenna (MIT)</a></span></footer>

			<script src=https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js integrity=sha384-ho+j7jyWK8fNQe+A12Hb8AhRq26LrZ/JpcUGGOn+Y7RsweNrtN/tE3MoK7ZeZDyx crossorigin=anonymous>
				
			</script>
			<script src=https://cdnjs.cloudflare.com/ajax/libs/feather-icons/4.28.0/feather.min.js></script>
			<script>feather.replace()
		</script>
	</body>
	</html>
