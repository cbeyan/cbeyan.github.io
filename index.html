<!-- Index Layout Start -->

<!DOCTYPE html>
<html lang="en">

<!-- HEAD Start -->

<head>
<ta name="google-site-verification" content="BwamyAdBwbb3W16Pg-duJAbybPSzRieEMXat_u23zps" />
    <meta charset="utf-8">
    
    <meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="description" content="Research page for Cigdem Beyan">
    <meta name="author" content="Cigdem Beyan">
    <meta name="keywords" content="cigdem, beyan, personal, research, social computing, multimedia, computer vision, machine learning, iit, edinburgh">
    <link rel="canonical" href="/">
    <title>Cigdem Beyan</title>

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link href="/css/grayscale.css" rel="stylesheet">

    <link href="/css/newsfeed.css" rel="stylesheet">
    <link href="/css/members.css" rel="stylesheet">

    <link href="/css/bootstrap-social.css" rel="stylesheet">
    <link href="/css/animate.min.css" rel="stylesheet">
	
<style>
	.blink-bg{
		color: #fff;
		padding: 10px;
		display: inline-block;
		border-radius: 5px;
		animation: blinkingBackground 2s infinite;
	}
	@keyframes blinkingBackground{
		0%		{ background-color: #10c018;}
		25%		{ background-color: #1056c0;}
		50%		{ background-color: #ef0a1a;}
		75%		{ background-color: #254878;}
		100%	        { background-color: #04a1d5;}
	}
</style>
	
	
    <!-- Custom Fonts -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link href="//fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" type="text/css">
    <link href="//fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="/css/rrssb.css" />
    <link href="/css/map.css" rel="stylesheet">

    <link rel="stylesheet" href="https://unpkg.com/leaflet@1.5.1/dist/leaflet.css" integrity="sha512-xwE/Az9zrjBIphAcBb3F6JVqxf46+CDLwfLMHloNu6KEQCAWi6HcDUbeOfBIptF7tcCzusKFjFw2yuvEpDL9wQ==" crossorigin="" />

      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
  <![endif]-->

    <link rel="shortcut icon" type="image/x-icon" href="/img/favicon.ico">

    <!-- iOS Web App mode -->

    <meta name="apple-mobile-web-app-capable" content="yes">
    <link rel="apple-touch-icon" sizes="36x36" href="/img/web-app/icon-36p.png">
    <link rel="apple-touch-icon" sizes="48x48" href="/img/web-app/icon-48p.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/img/web-app/icon-72p.png">
    <link rel="apple-touch-icon" sizes="96x96" href="/img/web-app/icon-96p.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/img/web-app/icon-144p.png">
    <link rel="apple-touch-icon" sizes="192x192" href="/img/web-app/icon-192p.png">

    <!-- Android Web App mode -->

    <link rel="manifest" href="/manifest.json">

    <!-- Chrome, Firefox OS and Opera -->
    <meta name="theme-color" content="#000000">
    <!-- Windows Phone -->
    <meta name="msapplication-navbutton-color" content="#000000">
    <!-- iOS Safari -->
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">



</head>

<!-- HEAD End -->

<body id="page-top" data-spy="scroll" data-target=".navbar-fixed-top" data-offset="151">

    <!-- Navigation Start -->

    <nav class="navbar navbar-custom navbar-fixed-top" role="navigation">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-main-collapse">
                    <i class="fa fa-bars"></i>
                </button>

                <a class="navbar-brand page-scroll" href="#page-top">

                    <div>

                        <!-- <div style="background-image: url('scratch.jpg');"> -->

                        <!--Cigdem Beyan-->
                    </div>
                </a>
            </div>
            <div class="collapse navbar-collapse navbar-right navbar-main-collapse">
                <ul class="nav navbar-nav">
		
			<li>
			<a class="page-scroll" href="#about"> <font color="736A00"> <h3>About </h3></font></a>

                    </li>

                    <li>

                        <a href="cbeyan_cv.pdf"> <font color="736A00"> <h3>Resume</h3></font> </a>

                    </li>

                    <li>

                        <a class="page-scroll" href="#selected-pub"> <font color="736A00"> <h3>Publications</font> </h3> </a>

                    </li>
	            <li>

                        <a class="page-scroll" href="#teaching"> <font color="736A00"> <h3>Teaching</font> </h3> </a>

                    </li>
			
			<li>

                        <a class="page-scroll" href="#research"> <font color="736A00"> <h3>Projects</font> </h3> </a>

                    </li>

                    <li>

                        <a class="page-scroll" href="#contact"> <font color="736A00"> <h3>Contact</font> </h3> </a>

                    </li>

                </ul>
            </div>
        </div>
    </nav>

    <!-- Navigation End -->

    <!-- Intro Start -->

    <header class="intro">

        <div class="intro-body">
            <div class="container">
                <div class="row">
                    <div class="col-md-10 col-md-offset-1">
                        <div style="min-height:150px"></div>

          <table style="width:100%">
  	   <tr>
	  
		<th></th>
                <th> <center>
			<img class="img-me" src="me_2.jpg" alt="Cigdem Beyan" style="width:25%;"></th>
			</center>
		<th></th>
          </tr>
	  <tr>
		<th></th>
                <th>
		<center>	<a class="btn btn-social-icon btn-xl btn-twitter" href="https://twitter.com/BeyanCigdem" ><i class="fa fa-twitter"></i></a>
                <a class="btn btn-social-icon btn-xl btn-linkedin" href="https://www.linkedin.com/in/cigdem-beyan-53954537" ><i class="fa fa-linkedin"></i></a>
                <a class="btn btn-social-icon btn-xl btn-google" href="https://scholar.google.com/citations?user=VmjUxckAAAAJ&hl=en" ><i class="fa fa-google"></i></a></th>
       		</center>
		  <th></th>
	</tr>
</table>

                        <h1 class="brand-heading">&nbsp;</h1>
                        <h1 class="brand-heading">&nbsp;</h1>

                        <h5>&nbsp;</h5>
                        <a href="#about" class="page-scroll">

                        </a>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <!-- Intro End -->

    <!-- About Start -->

    <section id="about" class="container content-section text-justify">
        <div class="row">
            <div class="col-md-10 col-md-offset-1">
                <h2 id="about">About</h2>
   
<p>
<b> Cigdem Beyan </b> is an Assistant Professor in Department of Information Engineering and Computer Science, <a href="https://webapps.unitn.it/du/it/Persona/PER0233089/Curriculum">University of Trento</a>, Italy. She is a part of the <a href="http://mhug.disi.unitn.it/">MHUG</a> research group, lead by <a href="https://scholar.google.it/citations?user=tNtjSewAAAAJ&hl=en">Prof. Nicu Sebe</a> and <a href="https://scholar.google.ca/citations?user=xf1T870AAAAJ&hl=en">Prof. Elisa Ricci</a>.
Her research interests are mainly in the areas of computer vision, machine learning, social signal processing, affective computing, and human/animal behaviour analysis.
	Prior to that, Cigdem was a postdoctoral researcher at Pattern Analysis and Computer Vision research line in Istituto Italiano di Tecnologia, Italy where she was collaborating with <a href="https://scholar.google.com/citations?user=yV3_PTkAAAAJ&hl=en">Prof. Vittorio Murino</a> and <a href="https://scholar.google.com/citations?user=LUzvbGIAAAAJ&hl=en">Dr. Alessio Del Bue</a>.</p>
		
	<p>Cigdem received her Ph.D. (2015) in School of Informatics, University of Edinburgh, UK, under supervision of <a href="https://scholar.google.co.uk/citations?user=LigYduEAAAAJ&hl=en">Prof. Robert B. Fisher</a>. Her thesis was a part of EU FP7 project called <a href="https://homepages.inf.ed.ac.uk/rbf/Fish4Knowledge/">Fish4Knowledge</a>, which includes fish behaviour understanding, trajectory analysis, anomaly detection, classification of imbalanced data, active learning and big data analysis. 
	She obtained her MSc. (2010) from School of Informatics, Middle East Technical University, Turkey, where she worked on computer vision topics: multiple object tracking, and abandoned object detection using thermal and visible band video data fusion.</p>

	    <p>In February 2022, Cigdem obtained <strong> National (Italian) Scientific Qualification to function as Associate Professor (Abilitazione Scientifica, Fascia II) </strong> in sections
01/B1 (<strong>Computer Science</strong>) and 09/H1 (<strong>Information Processing Systems</strong>). 		
Cigdem has co-authored more than 45 scientific publications and she regularly publishes in top-tier journals and conferences in computer vision, multimedia and social/affective computing. 

		    She is a reviewer of several multimedia, affective computing, computer vision and machine learning journals (e.g., IEEE Trans. PAMI, IEEE Trans. Multimedia; IEEE Trans. Affective Computing, Pattern Recognition), and IEEE/ACM/IAPR/BMVA conferences (e.g., CVPR, ECCV, ICML, WACV, ACM MM, BMVC, ACM ICMI, ICLR). 
		    She was selected as an Outstanding Reviewer in IEEE/CVF Computer Vision and Pattern Recognition Conference (CVPR) 2022. 
		    She was a Guest Co-Editor in <a href="https://www.frontiersin.org/research-topics/8447/computational-approaches-for-human-human-and-human-robot-social-interactions" > Frontiers in Robotics and AI </a>, 
		    and since September 2018 she is in the Editorial Board of <a href="https://academic.oup.com/icesjms">ICES Journal of Marine Science</a> covering area of applications of computer vision and machine learning in marine science. 
		    She has been an Area Chair in <a href="https://www.bmvc2021-virtualconference.com/people/area-chairs/">BMVC 2021</a>, <a href="https://icmi.acm.org/2022/people/">ACM ICMI 2022</a> and BMVC 2022.
		    She is the main organizer of <a href="https://sciar-workshop.github.io/"> Social and Cognitive Interactions for Assistive Robotics (SCIAR)</a> Workshop in IROS 2022, and has been  
		a co-organzier of Applications of Egocentric Vision Workshops (<a href="https://egoappworkshop.wordpress.com/">EgoApp2019</a> in BMVC 2019, <a href="https://egoappworkshop2020.wordpress.com/">EgoApp2020</a> in ICPR 2020). 
		    She is a member of IEEE, ACM and <a href="https://ellis.eu/members">ELLIS</a>.
		    She is an Associate Fellow of the Higher Education Academy in recognition of attainment against the UK Professional Standards Framework for teaching and learning support in higher education since 2014.
                                                </p>

                                                <h2 id="phd-students">Students</h2>
                                                <ul>
 <li>PhD thesis co-supervisor of Nicolo Carissimi in IIT (2015-2018)
 <p><i>Thesis Title: Investigating Social Interactions Using Multi-Modal Nonverbal Features </i></p></li>

<li>PhD thesis co-supervisor of Muhammad Shahid in IIT (2017-2020)
                                                        <p><i>Thesis Title: Social Interactions Analysis through Deep Visual Nonverbal Features</i></p>
						    </li>
							<li>PhD thesis co-supervisor of Giancarlo Paoletti in IIT (2019- )
							<p><i>Tentative Thesis Title: Unsupervised Skeleton-based Action Recognition</i></p>
                                                                                                            </li>
	<li>PhD thesis co-supervisor of Sanket Kumar Thakur in IIT (2020- )
							<p><i>Tentative Thesis Title: Interaction Analysis through Ego-centric Vision </i></p>
                                                                                                            </li>
	<li>Internship supervisor and Master thesis co-supervisor of Francesco Tonini in UniTN (2021-2022)
 <p><i>Topic: I Know Where You Are Looking At: Detecting People's Gaze With A Multimodal Approach  </i></p></li>
 
							<li>Internship supervisor of Martina Rama in UniTN (2021-2022)
 <p><i>Topic: Social Group Detection in Human-Robot Interaction Scenarios </i></p></li>
							


                                                </ul>

            </div>
        </div>
    </section>

    <!-- About End -->

    <!-- Selected Pub Preview Start -->

<div class="alt">
    <section id="selected-pub" class="container content-section text-justify">
	    <div class="row">
            <div class="col-md-10 col-md-offset-1">

                <h2 id="selected-pub">Selected Publications 
		    <a href="https://scholar.google.com/citations?user=VmjUxckAAAAJ&hl=en"><i>(All Publications)</i></a> </h2>
                

                
		    <div class="blink-bg"><h4><strong>    2021   </strong></h4></div>
		    
                    <strong> <p style="color:#736AFF">Unsupervised Human Action Recognition with Skeletal Graph Laplacian and Self-Supervised Viewpoints Invariance</strong>
                
<a href="https://github.com/IIT-PAVIS/UHAR_Skeletal_Laplacian">[code]</a>
<a href="https://www.researchgate.net/publication/355904430_Unsupervised_Human_Action_Recognition_with_Skeletal_Graph_Laplacian_and_Self-Supervised_Viewpoints_Invariance">[pdf]</a></p>
<p>G. Paoletti, J. Cavazza, C. Beyan, and A. Del Bue</p>

                <p><i>British Machine Vision Conference (BMVC) --- Oral presentation </i></p>
                <div>
                    <div style="float:left;width:20%;">
                        <p>
<iframe width="300" height="200" src="https://www.youtube.com/embed/xH_EW0l6Q8M" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
			    </p>
                    </div>
                    <div style="float:left;text-align: justify;width:80%;padding:10px;">
                    
                    </div>
                </div>
		    
      </div>

</div>
	
	 <div class="row">
		    <div class="col-md-10 col-md-offset-1">
				<strong> <p style="color:#736AFF">Predicting Gaze from Egocentric Social Interaction
Videos and IMU Data</strong>
                
<a href=="https://github.com/IIT-PAVIS/MultimodalGaze">[code]</a>
<a href="https://www.researchgate.net/publication/355379884_Predicting_Gaze_from_Egocentric_Social_Interaction_Videos_and_IMU_Data">[pdf]</a></p>
<p>S. Thakur, C. Beyan, P. Morerio, and A. Del Bu</p>

                <p><i>ACM International Conference on Multimodal Interaction (ICMI) </i></p>
                <div>
                    <div style="float:left;width:20%;">
                        <p>
<iframe width="300" height="200" src="https://www.youtube.com/embed/cBYsKOsZXPc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
			    </p>
                    </div>
                    <div style="float:left;text-align: justify;width:80%;padding:10px;">
                    
                    </div>
                </div>
	 
	      </div>
</div>
	
	
 <div class="row">
		    <div class="col-md-10 col-md-offset-1">
				<strong> <p style="color:#736AFF">Modeling Multiple Temporal Scales of Full-body
Movements for Emotion Classification</strong>
                
<a href="https://github.com/cbeyan/AffectiveBodyMovements">[code]</a>
<a href="https://www.researchgate.net/publication/353091498_Modeling_Multiple_Temporal_Scales_of_Full-body_Movements_for_Emotion_Classification">[pdf]</a></p>
<p>C. Beyan, S. Karumuri, G. Volpe, A. Camurri and R. Niewiadomski</p>

                <p><i>IEEE Transactions on Affective Computing </i></p>
                <div>
                    <div style="float:left;width:20%;">
                        <p>
<iframe width="300" height="200" src="https://www.youtube.com/embed/xdoXDnOf0oI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</p>
                    </div>
                    <div style="float:left;text-align: justify;width:80%;padding:10px;">
                    
                    </div>
                </div>
	 
	      </div>
</div>

	    <div class="row">
		    <div class="col-md-10 col-md-offset-1">
                    <strong> <p style="color:#736AFF">S-VVAD: Visual Voice Activity Detection by Motion Segmentation</strong>
                
<a href="https://github.com/IIT-PAVIS/S-VVAD">[code]</a> 
		    <a href="https://openaccess.thecvf.com/content/WACV2021/papers/Shahid_S-VVAD_Visual_Voice_Activity_Detection_by_Motion_Segmentation_WACV_2021_paper.pdf">[pdf]</a></p>
<p>M. Shahid, C. Beyan and V. Murino</p>

                <p><i>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</i></p>
                <div>
                    <div style="float:left;width:20%;">
                        <p>
<iframe width="300" height="200" src="https://www.youtube.com/embed/TN-KN5kpTkI" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</p>
                    </div>
                    <div style="float:left;text-align: justify;width:80%;padding:10px;">
                    
                    </div>
                </div>
            </div>
		    </div>

        <div class="row">
            <div class="col-md-10 col-md-offset-1">
		    
                <div class="blink-bg"><h4><strong>   2020   </strong></h4></div>
		    
		     <strong> <p style="color:#736AFF">Subspace Clustering for Action Recognition with Covariance Representations and Temporal Pruning</strong>               
<a href="https://github.com/IIT-PAVIS/subspace-clustering-action-recognition">[code]</a>
<a href="https://arxiv.org/abs/2006.11812">[pdf]</a></p>
<p>G. Paoletti, J. Cavazza, C. Beyan and A. Del Bue</p>

                <p><i>International Conference on Pattern Recognition (ICPR)</i></p>
                <div>
                    <div style="float:left;width:20%;">
                        <p>
<iframe width="300" height="200" src="https://www.youtube.com/embed/Vd_lvsfs3zw" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
			    </p>
                    </div>
                    <div style="float:left;text-align: justify;width:80%;padding:10px;">
                    
                    </div>
                </div>
            </div>
		</div>


	    <div class="row">
		    <div class="col-md-10 col-md-offset-1">
                    <strong> <p style="color:#736AFF">Analysis of Face-Touching Behavior in Large Scale Social Interaction Dataset</strong>
                
<a href="https://github.com/IIT-PAVIS/Face-Touching-Behavior">[code]</a>
			   <a href="https://www.researchgate.net/publication/346347593_Analysis_of_Face-Touching_Behavior_in_Large_Scale_Social_Interaction_Dataset">[pdf]</a></p> 
<p>C. Beyan, M. Bustreo, M. Shahid, G.L. Bailo, N. Carissimi and A. Del Bue</p>

                <p><i>ACM International Conference on Multimodal Interaction (ICMI)</i></p>
                <div>
                    <div style="float:left;width:20%;">
                        <p>

 <iframe width="300" height="200" src="https://www.youtube.com/embed/86VqUUZf0xU" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</p>
                    </div>
                    <div style="float:left;text-align: justify;width:80%;padding:10px;">
                    
                    </div>
                </div>
            </div>
		    </div>


        <div class="row">
            <div class="col-md-10 col-md-offset-1">


<strong> <p style="color:#736AFF">RealVAD: A Real-world Dataset and A Method for Voice Activity Detection by Body Motion Analysis</strong>
                
<a href="https://www.researchgate.net/publication/342729178_RealVAD_A_Real-world_Dataset_and_A_Method_for_Voice_Activity_Detection_by_Body_Motion_Analysis">[pdf+supp]</a>
<a href="https://github.com/IIT-PAVIS/Voice-Activity-Detection">[code]</a>
<a href="https://zenodo.org/record/3928151#.YZJ_HmDMKF4">[dataset]</a> </p>		
<p>C. Beyan, M. Shahid and V. Murino</p>

                <p><i>IEEE Transactions on Multimedia</i></p>
                <div>
                    <div style="float:left;width:20%;">
                        <p>
 <iframe width="300" height="200" src="https://www.youtube.com/embed/h_JZq1z4zZI" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

</p>
                    </div>
                    <div style="float:left;text-align: justify;width:80%;padding:10px;">
                    
                    </div>
                </div>
            </div>
        </div>


        <div class="row">
            <div class="col-md-10 col-md-offset-1">
		    
                <div class="blink-bg"><h4><strong>   2019   </strong></h4></div>

                
                    <strong> <p style="color:#736AFF">Personality Traits Classification Using Deep Visual Activity-based Nonverbal Features of Key-Dynamic Images</strong>
                
<a href="https://www.researchgate.net/publication/336152683_Personality_Traits_Classification_Using_Deep_Visual_Activity-based_Nonverbal_Features_of_Key-Dynamic_Images">[pdf+supp]</a> 
<p>C. Beyan, A. Zunino, M. Shahid, and V. Murino</p>

                <p><i>IEEE Transactions on Affective Computing</i></p>
                <div>
                    <div style="float:left;width:20%;">
                        <p><img src="publications/TAC2019_img.png"/ width="200%" height="200%"></p>
                    </div>
                    <div style="float:left;text-align: justify;width:80%;padding:10px;">
                    
                    </div>
                </div>
            </div>
        </div>


        <div class="row">
            <div class="col-md-10 col-md-offset-1">

                <p style="color:#736AFF"><strong>Voice Activity Detection by Upper Body Motion Analysis and Unsupervised Domain Adaptation
</strong>
                
<a href="https://www.researchgate.net/publication/339763147_Voice_Activity_Detection_by_Upper_Body_Motion_Analysis_and_Unsupervised_Domain_Adaptation">[pdf]</a>  </p>

<p>M. Shahid, C. Beyan, and V. Murino</p>
                <p></i>International Conference on Computer Vision Workshops (ICCVw) </i></p>

                <div>
                    <div style="float:left;width:20%;">
                        <p><img src="publications/ICCV2019_img.jpg"/ width="200%" height="200%"></p>
                    </div>
                    <div style="float:left;text-align: justify;width:80%;padding:10px;">
                  
                    </div>
                </div>

            </div>

        </div>

        <div class="row">
            <div class="col-md-10 col-md-offset-1">

                <p style="color:#736AFF"> <strong> A Sequential Data Analysis Approach to Detect Emergent Leaders in Small Groups</strong>
                
<a href="https://www.researchgate.net/publication/330641208_A_Sequential_Data_Analysis_Approach_to_Detect_Emergent_Leaders_in_Small_Groups">[pdf]</a> </p>

<p>C. Beyan, V.M. Katsageorgiou, and V. Murino</p>
                <p></i>IEEE Transactions on Multimedia</i></p>

                <div>
                    <div style="float:left;width:20%;">
                        <img src="publications/TMM2019_img.png"/ width="150%" height="150%">
                    </div>
                    <div style="float:left;text-align: justify;width:80%;padding:10px;">
                        
                    </div>
                </div>

            </div>

        </div>


        <div class="row">
            <div class="col-md-10 col-md-offset-1">
		    
<div class="blink-bg"><h4><strong>   2018   </strong></h4></div>
		    
                <p style="color:#736AFF"> <strong> Investigation of Small Group Social Interactions Using Deep Visual Activity-Based Nonverbal Features</strong>
                
<a href="publications/Poster_ACMMM_2018.pdf">[poster]</a> </p> 
<p>C. Beyan, M. Shahid, and V. Murino</p>
                <p><i>ACM International Conference on Multimedia (ACMMM)<i></p>

                <div>
                    <div style="float:left;width:20%;">
                        <img src="publications/ACMMM2018_img.png"/ width="200%" height="200%">
                    </div>
                    <div style="float:left;text-align: justify;width:80%;padding:10px;">
                    </div>
                </div>

            </div>

        </div>

<div class="row">
            <div class="col-md-10 col-md-offset-1">

                <p style="color:#736AFF"> <strong> Filling the Gaps: Predicting Missing Joints of Human Poses Using Denoising Autoencoders</strong>
                
<a href="https://www.researchgate.net/publication/330693927_Filling_the_Gaps_Predicting_Missing_Joints_of_Human_Poses_Using_Denoising_Autoencoders">[pdf]</a>  </p>
<p> N. Carissimi, P. Rota, C. Beyan, and V. Murino</p>
                <p> <i> European Conference on Computer Vision Workshops (ECCVw)</i></p>

                <div>
                    <div style="float:left;width:20%;">
                        <img src="publications/ECCVw2018.jpg"/ width="200%" height="200%">
                    </div>
                    <div style="float:left;text-align: justify;width:80%;padding:10px;">
                    </div>
                </div>

            </div>

        </div>

<div class="row">

            <div class="col-md-10 col-md-offset-1">
		    
<div class="blink-bg"><h4><strong>   2017   </strong></h4></div>
		    
                <p style="color:#736AFF"><strong> Multi-task Learning of Social Psychology Assessments and Nonverbal Features for Automatic Leadership Identification</strong>
                
<a href="publications/ICMI2017_poster.pdf">[poster]</a>  </p>
<p> C. Beyan, F. Capozzi, C. Becchio, and V. Murino</p>
                <p> <i>ACM International Conference on Multimodal Interaction (ICMI)</i></p>

                <div>
                    <div style="float:left;width:20%;">
                        <img src="publications/ICMI2017_img.png"/ width="200%" height="200%">
                    </div>
                    <div style="float:left;text-align: justify;width:80%;padding:10px;">
                    </div>
                </div>

            </div>

        </div>

<div class="row">
            <div class="col-md-10 col-md-offset-1">

                <p style="color:#736AFF"> <strong>Moving as a Leader: Detecting Emergent Leadership in Small Groups using Body Pose</strong>
                
<a href="publications/ACMMM2017_poster.pdf">[poster]</a> </p>
<p> C. Beyan, V. M. Katsageorgiou, and V. Murino</p>
                <p> <i>ACM International Conference on Multimedia (ACMMM)</i></p>

                <div>
                    <div style="float:left;width:20%;">
                        

                    </div>
                    <div style="float:left;text-align: justify;width:80%;padding:10px;">
                    </div>
                </div>

            </div>

        </div>

<div class="row">

            <div class="col-md-10 col-md-offset-1">

                <p style="color:#736AFF"> <strong>Prediction of the Leadership Style of an Emergent Leader Using Audio and Visual Nonverbal Features</strong>
                
<a href="https://www.researchgate.net/publication/319523845_Prediction_of_the_Leadership_Style_of_an_Emergent_Leader_Using_Audio_and_Visual_Nonverbal_Features">[pdf+supp]</a>
			<p> C. Beyan, F. Capozzi, C. Becchio, and V. Murino</p>
                <p><i> IEEE Transactions on Multimedia</i></p>

                <div>
                    <div style="float:left;width:20%;">

                        <img src="publications/TMM2017_img.png"/ width="200%" height="200%">

     
                    </div>
                    <!--<div style="float:left;text-align: justify;width:80%;padding:10px;">
                    </div>-->
                </div>

            </div>

        </div>

<div class="row">
            <div class="col-md-10 col-md-offset-1">
		    
<div class="blink-bg"><h4><strong>   2016   </strong></h4></div>
		    
                <p style="color:#736AFF"> <strong> Detecting Emergent Leader in a Meeting Environment Using Nonverbal Visual Features Only</strong>
                
<a href="publications/ICMI2016_main.pdf">[poster]</a></p>
<p> C. Beyan, N. Carissimi, F. Capozzi, S. Vascon, M. Bustreo, A. Pierro, C. Becchio and V. Murino</p>		     
                <p> ACM International Conference on Multimodal Interaction (ICMI)</p>

                <div>
                    <div style="float:left;width:20%;">
                         
                    </div>
                    <div style="float:left;text-align: justify;width:80%;padding:10px;">
                    </div>
                </div>

            </div>

        </div>

        </div>


    </section>
</div>

        <!-- Teaching Start -->
        <section id="teaching" class="container content-section text-justify">
            <div class="row">
                <div class="col-md-10 col-md-offset-1">
                    <h2 id="teaching">Teaching</h2>
			
			<ul>
			<li> <h5> <a href="https://ict.unitn.it/node/1165">Multimodal Machine Learning</a> (PhD Course, 10 hours, Online, in English)</h5> </li>
                        <li> <h5> <a href="https://www.esse3.unitn.it/Guide/PaginaADErogata.do?ad_er_id=2021*N0*N0*S2*53694*93492&ANNO_ACCADEMICO=2021&codice_docente=77997&mostra_percorsi=S">Introduction to Machine Learning </a> (Laurea Magistrale, CFU=6, 24 hours, Co-located, in English) </h5>
		        </li>
			<li> <h5>  <a href="https://www.i-aida.org/course/human-behavior-analysis-with-a-social-signal-processing-perspective/">AIDA Short Course</a> (PhD and Young Researchers Course, 4 hours, Online, in English) </h5>
			
		         
                         </li>
				</ul>
		    </div>
            </div>
        </section>

        <!-- Teaching End -->


<!-- Research Start -->
        <section id="research" class="container content-section text-justify">
            <div class="row">
                <div class="col-md-10 col-md-offset-1">
                    <h2 id="contact">Current Funded Projects</h2>
			<ul>
			<li> <h5>Computer Vision to Expand Monitoring and Accelerate Assessment of Coastal Fish 
				<a href="https://fishlarvae.org/activities/current-projects/">(CoastVision)</a></h5> 
				<p>
					<h6> Role: Co-investigator (Local PI, fundraiser)</h6>
				</p>
			        <p>
				        <h6> Short Description: CoastVision uses the power of deep learning to refine and extend a computer vision pipeline for detecting, classifying and sizing the key fish species in shallow water coastal ecosystems, facilitating a transition to fully automated video analysis. Computer vision for re-identifying individuals solely based on their unique visible features is also developed. 
				</h6>	
				</p>	
				</li>
                        <li> <h5>Assistive Robots wiTh EMotIonal Skills <a href="https://www.fondazionevrt.it/7-next-generation-2021">(ARTEMIS)</a></h5>
				<p> <h6> Role: Co-PI (together with Prof. Elisa Ricci and Dr. Federica Arrigoni) </h6>
				</p>
				<p> <h6> Short Description: ARTEMIS aims to develop new approaches based on artificial intelligence methods that allow social robots to interpret the emotional states of patients and assess their level of comfort in interacting with the robot. </h6>
				</p>
		        </li>
			<li> <h5><a href="https://www.ai4media.eu/">AI4Media</a> EU Horizon 2020 (GA No. 951911)</h5>
				<p>
					<h6> Role: Participant 
					</h6>
				</p>
				<p>
					<h6> Short Description: AI4Media project aims to deliver the next generation of core AI advances and training to serve the Media sector, while ensuring that the European values of ethical and trustworthy AI are embedded in future AI deployments. 
					</h6>
				</p>
			
                         </li>

				<li> <h5>Socially Pertinent Robots in Gerontological Healthcare <a href="https://spring-h2020.eu/">(SPRING)</a> EU Horizon 2020 (GA No. 871245)</h5>
				<p>
					<h6> Role: Participant 
					</h6>
				</p>
				<p>
					<h6> Short Description: SPRING project focuses on Socially Assistive Robots (SARs) and their applications in healthcare and psychological well-being. The goal is to develop a novel paradigm of socially-aware robots, grounded on modern statistical and deep-learning methods, and harnessed by state-of-the-art algorithms for computer vision, audio-signal processing, sensor-based robot control, and spoken dialog systems
					</h6>
				</p>
			
                         </li>
				</ul>
			
			
                </div>
            </div>
        </section>

        <!-- Research End -->



        <!-- Contact Start -->
        <section id="contact" class="container content-section text-justify">
            <div class="row">
                <div class="col-md-10 col-md-offset-1">
                    <h2 id="contact">Contact</h2>
			
			
			<h5>name[dot]surname[at]unitn[dot][it]</h5>
                    <h5>Via Sommarive, 5 - 38123 Povo, Italia</h5>
                </div>
            </div>
        </section>

        <!-- Contact End -->

        <!-- Javascript Start -->

        <!-- jQuery -->
        <script src="https://code.jquery.com/jquery-1.11.3.min.js"></script>

        <!-- Bootstrap Core JavaScript -->
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>

        <!-- Plugin JavaScript -->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>

        <!-- Custom Theme JavaScript -->
        <!--* Start Bootstrap - Grayscale Bootstrap Theme (http://startbootstrap.com)
* Code licensed under the Apache License v2.0.
* For details, see http://www.apache.org/licenses/LICENSE-2.0.-->
        <script>
            function toggleNavCollapse() {
                50 < $(".navbar").offset().top ? $(".navbar-fixed-top").addClass("top-nav-collapse") : $(".navbar-fixed-top").removeClass("top-nav-collapse");
            }
            $(document).ready(toggleNavCollapse);
            $(window).scroll(toggleNavCollapse);
            $(function() {
                $("a.page-scroll").bind("click", function(b) {
                    var a = $(this);
                    $("html, body").stop().animate({
                        scrollTop: $(a.attr("href")).offset().top - 50
                    }, 1500, "easeInOutExpo", function() {
                        a.blur()
                    });
                    b.preventDefault()
                })
            });
            $(".navbar-collapse ul li a").click(function() {
                $(".navbar-toggle:visible").click()
            });
        </script>

        <!-- Collapse navbar when navbar-brand is clicked -->

        <script>
            $(function() {
                $(".navbar-brand").click(function() {
                    $(".collapse.in") && $(".collapse.in").animate({
                        height: "1px"
                    }, 500, function() {
                        $(".collapse.in").removeClass("in")
                    })
                })
            });
        </script>

        <!-- Google Tracking Id Start -->
        <script>
            (function(i, s, o, g, r, a, m) {
                i['GoogleAnalyticsObject'] = r;
                i[r] = i[r] || function() {
                    (i[r].q = i[r].q || []).push(arguments)
                }, i[r].l = 1 * new Date();
                a = s.createElement(o),
                    m = s.getElementsByTagName(o)[0];
                a.async = 1;
                a.src = g;
                m.parentNode.insertBefore(a, m)
            })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
            ga('create', 'UA-7794553-6', 'auto');
            ga('send', 'pageview');
        </script>

        <!-- Google Tracking Id End -->

        <!-- Disqus -->

        <!-- Comments Counter Start -->

        <script type="text/javascript">
            
            var disqus_shortname = 'journal'; // required: replace example with your forum shortname

            
            (function() {
                var s = document.createElement('script');
                s.async = true;
                s.type = 'text/javascript';
                s.src = '//' + disqus_shortname + '.disqus.com/count.js';
                (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
            }());
        </script>

        <!-- Comments Counter End -->

        <!-- Dynamic Typing Start -->

        <script type="text/javascript" src="/js/typed.min.js"></script>
        <script type="text/javascript">
            var myQuotes = new Array();

            myQuotes.push("Researcher Italian Institute of Technology");

               myQuotes.push("Computer Vision, Machine Learning, Social Signal Processing, ...");

            function shuffle(array) {
                var currentIndex = array.length,
                    temporaryValue, randomIndex;

                // While there remain elements to shuffle...
                while (0 !== currentIndex) {

                    // Pick a remaining element...
                    randomIndex = Math.floor(Math.random() * currentIndex);
                    currentIndex -= 1;

                    // And swap it with the current element.
                    temporaryValue = array[currentIndex];
                    array[currentIndex] = array[randomIndex];
                    array[randomIndex] = temporaryValue;
                }

                return array;
            }

            $(".intro-text").typed({
                strings: myQuotes,
                typeSpeed: 10,
                backDelay: 5000,
                startDelay: 200,
                loop: true,
                loopCount: false,
                cursorChar: "|"
            });
        </script>

        <!-- Dynamic Typing End  -->

        <script>
            function addTohistory() {
                if (!window.location.host.startsWith("127.0.0.1")) {
                    history.pushState({}, '', '/');
                }
            }
        </script>

        <!-- Gesture Navigation / Swipe Instruction Start -->

        <!-- Gesture Navigation / Swipe Instruction End -->

        <script src="/js/wow.min.js"></script>
        <script src="https://unpkg.com/leaflet@1.5.1/dist/leaflet.js" integrity="sha512-GffPMF3RvMeYyc1LWMHtK8EbPv0iNZ8/oTtHPx9/cc2ILxQ+u905qIwdpULaqDkyBKgOaB57QTMg7ztg8Jm2Og==" crossorigin=""></script>
        <script src="/js/map.js"></script>
        <!-- Javascript End -->

</body>

</html>
